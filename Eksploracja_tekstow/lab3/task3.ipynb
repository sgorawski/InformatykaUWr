{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 3. (5p)** Napisz program, który przeglądając 1-gramy i 2-gramy (nkjp ngrams) z języka\n",
    "polskiego znajdzie możliwie najwięcej sytuacji, w których popełniono literówkę związaną z wstawieniem, bądź pominięciem spacji. Wystarczy, że znajdziesz w sumie około 10 tysięcy błędów, ale\n",
    "postaraj się, by były one możliwie jak najbardziej wiarygodne. Przykładowo, dla zadania wstawiania\n",
    "spacji:\n",
    "- Powinieneś znaleźć takie przykłady jak: wielkiegopomorska, socjologiiuniwersytetu, otwartapracownia, przezgrzechy\n",
    "- **Nie** powinieneś znajdować: antysystemową, supertygrysa, wewnątrzoddziałowego, wschodniokarpackiego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIGRAMS_FILE_PATH = 'data/1grams'\n",
    "BIGRAMS_FILE_PATH = 'data/2grams'\n",
    "\n",
    "BASE_FORMS_FILE_PATH = 'data/polimorfologik-2.1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(BASE_FORMS_FILE_PATH) as f:\n",
    "    _BASE_FORMS = {\n",
    "        word.lower(): base.lower()\n",
    "        for base, word, *__ in csv.reader(f, delimiter=';')\n",
    "    }\n",
    "\n",
    "def base(word):\n",
    "    return _BASE_FORMS.get(word.lower())\n",
    "\n",
    "def is_correct(word):\n",
    "    return base(word) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "_WORD_COUNTS = defaultdict(int)\n",
    "with open(UNIGRAMS_FILE_PATH) as f:\n",
    "    for line in f:\n",
    "        count_raw, word = line.split()\n",
    "        _WORD_COUNTS[base(word)] += int(count_raw)\n",
    "    \n",
    "def get_count(word):\n",
    "    return _WORD_COUNTS.get(base(word), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_COUNT = 1000\n",
    "\n",
    "def is_likely(word):\n",
    "    return is_correct(word) and get_count(word) > MIN_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_SPACE_PREFIXES = {\n",
    "    'anty',\n",
    "    'przeciw',\n",
    "    'super',\n",
    "    'wewnątrz',\n",
    "    'ogólno',\n",
    "    'ponad',\n",
    "    'auto',\n",
    "    'pod',\n",
    "    'poz',\n",
    "    'pan',\n",
    "    'cie',\n",
    "    'lub',\n",
    "    'nie',\n",
    "    'kar',\n",
    "    'sto',\n",
    "    'nowo',\n",
    "    'mało',\n",
    "    # NUMERBS\n",
    "    'jedno',\n",
    "    'dwu',\n",
    "    'trzy',\n",
    "    'cztero',\n",
    "    'pięcio',\n",
    "    'sześcio',\n",
    "    'siedmio',\n",
    "    'ośmio',\n",
    "    'dziewięcio',\n",
    "    'dziesięcio',\n",
    "    # DIRECTIONS\n",
    "    'wschodnio',\n",
    "    'zachodnio',\n",
    "    'północno',\n",
    "    'południowo',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def was_space_wrongly_omitted(word):\n",
    "    if is_correct(word):\n",
    "        return False\n",
    "    try:\n",
    "        prefix, suffix = next(\n",
    "            (word[:i], word[i:])\n",
    "            for i in range(1, len(word))\n",
    "            if is_likely(word[:i]) and is_likely(word[i:])\n",
    "        )\n",
    "    except StopIteration:\n",
    "        return False\n",
    "    return all([\n",
    "        len(prefix) >= 3,\n",
    "        len(suffix) >= 3,\n",
    "        len(prefix) >= len(word) / 3,\n",
    "        len(suffix) >= len(word) / 3,\n",
    "        prefix not in NO_SPACE_PREFIXES,\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def was_space_wrongly_inserted(word1, word2):\n",
    "    return (\n",
    "        is_likely(word1 + word2)\n",
    "        and (not is_likely(word1) or not is_likely(word2))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_likely('poz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS1_FILE_PATH = 'results/3_1.txt'\n",
    "\n",
    "with open(RESULTS1_FILE_PATH, 'w+') as res:\n",
    "    with open(UNIGRAMS_FILE_PATH) as f:\n",
    "        for line in f:\n",
    "            _, word = line.split()\n",
    "            if was_space_wrongly_omitted(word):\n",
    "                res.write(f'{word}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "was_space_wrongly_omitted('krzysztof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_correct('vito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORD_COUNTS.get('morzem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20975"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_count('mama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mama'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base('mama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS2_FILE_PATH = 'results/3_2.txt'\n",
    "\n",
    "with open(RESULTS2_FILE_PATH, 'w+') as res:\n",
    "    with open(BIGRAMS_FILE_PATH) as f:\n",
    "        for line in f:\n",
    "            _, word1, word2 = line.split()\n",
    "            if was_space_wrongly_inserted(word1, word2):\n",
    "                res.write(f'{word1} {word2}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
