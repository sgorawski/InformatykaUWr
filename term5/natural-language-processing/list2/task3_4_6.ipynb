{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPERTAGS_FILEPATH = '../data/supertags.txt'\n",
    "BIGRAMS_FILEPATH = '../data/poleval_2grams.txt'\n",
    "PAN_TADEUSZ_FILEPATH = '../data/pan-tadeusz.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGS = {}\n",
    "with open(SUPERTAGS_FILEPATH) as f:\n",
    "    for line in f:\n",
    "        word, tag = line.split()\n",
    "        TAGS[word] = tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_of(word):\n",
    "    word_ = word.lower()\n",
    "    return TAGS.get(word_, f'^{word_}'[-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unigram stats, doubled but it doesnt matter\n",
    "UNIGRAMS_BY_TAG = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "with open(BIGRAMS_FILEPATH) as f:\n",
    "    for line in f:\n",
    "        count_raw, word1, word2 = line.split()\n",
    "        tag1 = tag_of(word1)\n",
    "        tag2 = tag_of(word2)\n",
    "        count = int(count_raw)\n",
    "        UNIGRAMS_BY_TAG[tag1][word1] += count\n",
    "        UNIGRAMS_BY_TAG[tag2][word2] += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ug(word):\n",
    "    \"\"\"Generate a similar word using unigrams\"\"\"\n",
    "    tag = tag_of(word)\n",
    "    ug = UNIGRAMS_BY_TAG[tag]\n",
    "    pop, w = list(ug.keys()), list(ug.values())\n",
    "    return random.choices(pop, w)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_by_tags(text):\n",
    "    \"\"\"Input must be tokenized\"\"\"\n",
    "    words = text.split()\n",
    "    res = (gen_ug(word) for word in words)\n",
    "    return ' '.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLES = \"\"\"\n",
    "Mały Piotruś spotkał w niewielkiej restauracyjce wczoraj poznaną koleżankę .\n",
    "Dwa razy ostra baranina na grubym !\n",
    "Litwo , ojczyzno moja , Ty jesteś jak zdrowie\n",
    "Zapraszam wszystkich do wrzucania swoich implementacji w różnych językach w komentarzach .\n",
    "Szanuję twórcę za talent , ale nawet się nie uśmiechnąłem\n",
    "Mam takie skromne marzenie dotyczące uniwersum Harrego Pottera\n",
    "Eksperymenty przeprowadza się na studentach , bo jest ich dużo i na szczurach , bo są inteligentne .\n",
    "\"\"\".split('\\n')[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "śląski paweł zbadał do nieoficjalnej sprawie jeśli cytowaną inflację .\n",
      "dwa dni indywidualna firma i następnym !\n",
      "warto , kolo taka , ty jesteś jak ostrze\n",
      "spodziewam których w wyposażenia niektórych noweli w sejmowych zakładach dla krajach .\n",
      "informuję pracodawcę w druk , się trzeba dla nie spróbowałem\n",
      "mam które fantazyjne morze odpowiadające prezydium mikroostrożnościowego infoafera\n",
      "hotele zajmuje na w podatnikach , przez jest ich na o i bezkręgowcach , się są publiczne .\n"
     ]
    }
   ],
   "source": [
    "for example in EXAMPLES:\n",
    "    print(generate_by_tags(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigram stats\n",
    "BIGRAMS_BY_TAG_BY_PREV = collections.defaultdict(\n",
    "    lambda: collections.defaultdict(\n",
    "        lambda: collections.defaultdict(int)\n",
    "    )\n",
    ")\n",
    "with open(BIGRAMS_FILEPATH) as f:\n",
    "    for line in f:\n",
    "        count_raw, word1, word2 = line.split()\n",
    "        count = int(count_raw)\n",
    "        tag2 = tag_of(word2)\n",
    "        BIGRAMS_BY_TAG_BY_PREV[word1][tag2][word2] += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_bg(prev, word):\n",
    "    \"\"\"Generate a similar word using bigrams,\n",
    "    prev is previously generated here, not source\n",
    "    \"\"\"\n",
    "    tag = tag_of(word)\n",
    "    bgs = BIGRAMS_BY_TAG_BY_PREV[prev][tag]\n",
    "    if not bgs:\n",
    "        return None\n",
    "    pop, w = list(bgs.keys()), list(bgs.values())\n",
    "    return random.choices(pop, w)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_by_tags2(text):\n",
    "    \"\"\"Input must be tokenized\"\"\"\n",
    "    words = text.split()\n",
    "    word = words.pop(0)\n",
    "    # generate first by unigram\n",
    "    res = [gen_ug(word)]\n",
    "    for word in words:\n",
    "        nxt = gen_bg(res[-1], word) or f'| {gen_ug(word)}'\n",
    "        res.append(nxt)\n",
    "    return ' '.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zgodny kumpel zakupił w niewłaściwej obsłudze i przemyślaną decyzję .\n",
      "dwa razy można kilka wcześniej wyjazdowym | !\n",
      "sporo , warto ta , ty jesteś jak dokowanie\n",
      "informuję wszystkich z morza | niektórych | pracy | w | pielęgniarskich | lasach | i | aktach | .\n",
      "wyjaśniam | rzeczoznawcę | w | program | , | poprzez | że | przecież | nie | przyjąłem\n",
      "mam takie mądre bieganie | dotyczące | centrum | antyawarskiego | altera\n",
      "zawody organizuje się na polakach , z jest ich o delhi w sokołach , że są rzetelne .\n"
     ]
    }
   ],
   "source": [
    "for example in EXAMPLES:\n",
    "    print(generate_by_tags2(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTERS_PL = set('aąbcćdeęfghijklłmnńoópqrsśtuvwxyzżź')\n",
    "VOWELS_PL = set('aeyioąęuó')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sylc_in(word_raw):\n",
    "    word_ = f'{word_raw}^'\n",
    "    sylc = 0\n",
    "    for i in range(len(word_raw)):\n",
    "        # I know, I know\n",
    "        if word_[i] == 'i' and word_[i + 1] in VOWELS_PL:\n",
    "            pass\n",
    "        elif word_[i] in VOWELS_PL:\n",
    "            sylc += 1\n",
    "    return sylc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(text_raw):\n",
    "    words_raw = text_raw.lower().split()\n",
    "    res = []\n",
    "    for word_raw in words_raw:\n",
    "        res.append(sylc_in(word_raw))\n",
    "    return tuple(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taginate(text_raw):\n",
    "    buf = []\n",
    "    tokens = []\n",
    "    for ch in text_raw.lower():\n",
    "        if ch in LETTERS_PL:\n",
    "            buf.append(ch)\n",
    "        elif buf:\n",
    "            tokens.append(''.join(buf))\n",
    "            buf.clear()\n",
    "    return tuple(tag_of(token) for token in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT_SYLLABLE_COUNTS = set()\n",
    "PT_TAG_SEQS = set()\n",
    "with open(PAN_TADEUSZ_FILEPATH) as f:\n",
    "    for line in f:\n",
    "        sylc = count_syllables(line)\n",
    "        tags = taginate(line)\n",
    "        PT_SYLLABLE_COUNTS.add(sylc)\n",
    "        PT_TAG_SEQS.add(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _next(sylc, tag, rhyme=''):\n",
    "    ug = UNIGRAMS_BY_TAG[tag]\n",
    "    words = [k for k in ug if k.endswith(rhyme) and sylc_in(k) == sylc]\n",
    "    if not words:\n",
    "        return None\n",
    "    w = [ug[k] for k in words]\n",
    "    return random.choices(words, w)[0]\n",
    "\n",
    "def gen_pt_line(rhyme='', *, max_iter=10_000):\n",
    "    \"\"\"Try random tags and syllable counts\n",
    "    until a line is generated. Generation is\n",
    "    done in reverse order for rhyming performance.\n",
    "    \"\"\"\n",
    "    iterc = 0\n",
    "    tag_opts = list(PT_TAG_SEQS.copy())\n",
    "    random.shuffle(tag_opts)\n",
    "    for tags_line in tag_opts:\n",
    "        sylc_opts = [\n",
    "            scl for scl in PT_SYLLABLE_COUNTS\n",
    "            if len(scl) == len(tags_line)\n",
    "        ]\n",
    "        random.shuffle(sylc_opts)\n",
    "        for sylc_line in sylc_opts:\n",
    "            iterc += 1\n",
    "            if iterc > max_iter:\n",
    "                return None\n",
    "            buf = []\n",
    "            last = len(sylc_line) - 1\n",
    "            for i, (sylc, tag) in enumerate(zip(\n",
    "                reversed(sylc_line), reversed(tags_line)\n",
    "            )):\n",
    "                rhm = rhyme if i == 0 else ''\n",
    "                nxt = _next(sylc, tag, rhm)\n",
    "                if nxt is None:\n",
    "                    break\n",
    "                buf.append(nxt)\n",
    "                if i == last:\n",
    "                    return ' '.join(reversed(buf))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rhyme(line):\n",
    "    \"\"\"Get line ending to last-but-one vowel\"\"\"\n",
    "    buf = []\n",
    "    lbo = True\n",
    "    line_ = f'^{line}'\n",
    "    for i in range(len(line), -1, -1):\n",
    "        buf.append(line_[i])\n",
    "        if line_[i] in VOWELS_PL:\n",
    "            if line_[i - 1] == 'i':\n",
    "                continue\n",
    "            if not lbo:\n",
    "                return ''.join(reversed(buf))\n",
    "            lbo = False\n",
    "\n",
    "def gen_pt_diverse(max_tries=100, max_line_iter=5000):\n",
    "    for _ in range(max_tries):\n",
    "        fst = gen_pt_line(max_iter=max_line_iter)\n",
    "        if fst is None:\n",
    "            break\n",
    "        rhyme = get_rhyme(fst)\n",
    "        snd = gen_pt_line(rhyme, max_iter=max_line_iter)\n",
    "        if snd:\n",
    "            return fst, snd\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w mnie żyje mdły niektóry szwank ocena jaki\n",
      "ale odpowiednią swą mszą wówczas rybaki\n",
      "nej nich miękkości zawarte orderem\n",
      "samce aby w hałd albo dnia wręczyli erem\n",
      "jako goście najmu na oleju dostali\n",
      "że mimo co za wejściu mam i powiem zali\n",
      "woż zdał wroński pochodził to temat ostatni\n",
      "tutaj właśnie i chcemy ktoś kogo uzdatni\n",
      "wieść do miejscu przy grze na do sprzedaży jana\n",
      "pije nie wyłącznie trio się a grę tytana\n",
      "później oraz czy podjął praw butów zasiadał\n",
      "mogę kto 100-latków śmierci mszę wyspowiadał\n",
      "bardziej trendami i skracano ręce\n",
      "się świecie domuchowski według tak książęce\n",
      "i tylko habbaniji łza świętego pana\n",
      "a grając z odnotowuję internet wymiana\n",
      "cele tańczą także pan ich realizuje\n",
      "za zostało do weszli więc cny tu pracuje\n",
      "się nim wieszczył pan poseł oraz w apollonie\n",
      "porucznik wyniósł zwierzaka tytonie\n",
      "z znalazłem określenia według gry waszeci\n",
      "ktokolwiek niej nie zleci\n",
      "zamieszkała tri była w spadła zatrudniona\n",
      "przez ciasno bez tych upraw miłością nie śledziona\n",
      "ambasadą akcje jak złem trwać zdrowia władze\n",
      "o nikt bliżej nas pomóc nie trwa psiemu hadze\n",
      "skutkowały także raz pacjentów pluskwiaki\n",
      "odrzuciła nagrała podczas jest cwaniaki\n",
      "chce mdły kapelan żeby bankowej ochronie\n",
      "do kierunki ale giej pełnił ochronie\n",
      "mogliśmy przeciwko i bardzkim wystąpieniu\n",
      "że filmie a teraz w-wie się pgkim światłocieniu\n",
      "podjąć akumulator pcham zrobić czas dzieci\n",
      "wspiąłem jedynym niem trzech pokojowych kmieci\n",
      "msza je wpisując przede ekstraklasy pani\n",
      "pomimo prwie brano uczelni dejmani\n",
      "zdobywając do w wersja i jana zabierze\n",
      "i to jest głos cny że nim jedno na alkierze\n",
      "społecznie w go wpłynęła nasza psia ustawa\n",
      "ja w zły począwszy any pracował jak sprawa\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    dv = gen_pt_diverse()\n",
    "    if dv:\n",
    "        print('\\n'.join(dv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
